{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST + MLP\n",
    "\n",
    "In this notebook, we design and train a Multi-Layer Perceptrons (MLP) for hand-written digit classification task. We use MNIST dataset that contains 28x28 pixel images of a hand-written digit (0 to 9, so 10 classification targets). \n",
    "\n",
    "## Goals\n",
    "1. Get familiar with MNIST dataset\n",
    "2. Build a pipeline to stream data for SGD\n",
    "3. Design MLP and train on MNIST\n",
    "\n",
    "Let's start with usual import!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x70215f339b10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import drawing tools, set style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "# Import numpy and torch, set default device based on GPU availability\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device(device)\n",
    "\n",
    "# Set the seed to always get the same result from RNG calls in this notebook\n",
    "SEED = 12345\n",
    "np.random.seed(SEED)    # Setting the seed for reproducibility\n",
    "torch.manual_seed(SEED) # This is how you do for torch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST Dataset\n",
    "MNIST is widely used for an introductory machine learning (ML) courses/lectures. Most, if not all, ML libraries provide an easy way (API) to access MNIST and many other publicly available dataset. This is true in `PyTorch` as well. MNIST dataset in the form of a `Dataset` instance is available from `torchvision`. \n",
    "\n",
    "A `torchvision` is a supporting module that has many image-related APIs including an interface (and management) of MNIST dataset. Let's see how we can construct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Data file download directory\n",
    "LOCAL_DATA_DIR = './mnist-data'\n",
    "\n",
    "# Use prepared data handler from pytorch (torchvision)\n",
    "dataset = datasets.MNIST(LOCAL_DATA_DIR, train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, MNIST is also a type `Dataset` (how? through class inheritance). All torch `Dataset` instance have two useful and common methods: the length method and data element access via index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# Length of the MNIST dataset\n",
    "print( len(dataset)  )\n",
    "\n",
    "# Type of the first element in the MNIST dataset\n",
    "print( type(dataset[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That being said, how each data element is presented depends on a particular `Dataset` implementation. In case of MNIST, it is a tuple of length 2: **data** and **label**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data  : <class 'torch.Tensor'> shape torch.Size([1, 28, 28])\n",
      "Type of label : <class 'int'> value 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Access a specific entry in the MNIST dataset\n",
    "ENTRY=0\n",
    "data, label = dataset[ENTRY]\n",
    "\n",
    "# Show the type of data and the type of label associated with it\n",
    "print('Type of data  :', type(data),  'shape', data.shape)\n",
    "print('Type of label :', type(label), 'value', label)\n",
    "\n",
    "# Use matplotlib to draw the data as an image\n",
    "data = data.view(data.shape[1:])\n",
    "plt.imshow(data,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"dataloader\"></a>\n",
    "## 2. Streaming MNIST data using `DataLoader`\n",
    "\n",
    "Pytorch (and any other ML libraries out there) provides a generalized tool to interface an iteratable data instance called `DataLoader`. This is a useful tool for streaming data in a typical ML workflow. \n",
    "\n",
    "1. iteratable batching of data\n",
    "2. custom data sampling (random provided by default)\n",
    "3. custom data pre-processing\n",
    "4. parallel data reading\n",
    "\n",
    "Let's play a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vanilla data loader\n",
      "0 tensor([0])\n",
      "1 tensor([1])\n",
      "2 tensor([2])\n",
      "3 tensor([3])\n",
      "4 tensor([4])\n",
      "5 tensor([5])\n",
      "6 tensor([6])\n",
      "7 tensor([7])\n",
      "8 tensor([8])\n",
      "9 tensor([9])\n",
      "\n",
      "... batch_size set to 3\n",
      "0 tensor([0, 1, 2])\n",
      "1 tensor([3, 4, 5])\n",
      "2 tensor([6, 7, 8])\n",
      "3 tensor([9])\n",
      "\n",
      "... + drop_last set to True\n",
      "0 tensor([0, 1, 2])\n",
      "1 tensor([3, 4, 5])\n",
      "2 tensor([6, 7, 8])\n",
      "\n",
      "... + shuffle set to True\n",
      "0 tensor([7, 3, 2])\n",
      "1 tensor([6, 1, 0])\n",
      "2 tensor([5, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define basic dataset of 10 integers from 0 to 9\n",
    "# It fits the definition of a torch dataset because it has\n",
    "# a __len__ and a __getitem__ method\n",
    "data = np.arange(10)\n",
    "\n",
    "# Initialize a basic sequential dataloader, check how the values are fetched\n",
    "print('\\nVanilla data loader')\n",
    "loader = DataLoader(data)\n",
    "for index, batch_data in enumerate(loader):\n",
    "    print(index, batch_data)\n",
    "\n",
    "# Batch the data by groups of 3 (batch_size=3), check how the values are fetched\n",
    "print('\\n... batch_size set to 3')\n",
    "loader = DataLoader(data, batch_size=3)\n",
    "for index, batch_data in enumerate(loader):\n",
    "    print(index,batch_data)\n",
    "\n",
    "# Now drop the last batch if the length is < 3, check how the values are fetched\n",
    "print('\\n... + drop_last set to True')\n",
    "loader = DataLoader(data, batch_size=3, drop_last=True)\n",
    "for index, batch_data in enumerate(loader):\n",
    "    print(index,batch_data)\n",
    "\n",
    "# Finally, shuffle the input randomly because batching it\n",
    "print('\\n... + shuffle set to True')\n",
    "loader = DataLoader(data, batch_size=3, drop_last=True, shuffle=True)\n",
    "for index, batch_data in enumerate(loader):\n",
    "    print(index,batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wrap the data loading loop by another loop so that we can continue iterating our dataset indefinitely for optimizing our model over **1 epoch** (full dataset loop). But if you want a reproducibility of the data subsets created by `DataLoader`, you can set the random seed explicitly as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0\n",
      "0 tensor([9, 0, 5])\n",
      "1 tensor([1, 6, 7])\n",
      "2 tensor([2, 3, 4])\n",
      "Loop 1\n",
      "0 tensor([3, 5, 7])\n",
      "1 tensor([4, 1, 6])\n",
      "2 tensor([2, 9, 0])\n",
      "\n",
      "Repeating by setting the seed\n",
      "Loop 0\n",
      "0 tensor([4, 2, 0])\n",
      "1 tensor([6, 8, 7])\n",
      "2 tensor([9, 1, 5])\n",
      "Loop 1\n",
      "0 tensor([4, 2, 0])\n",
      "1 tensor([6, 8, 7])\n",
      "2 tensor([9, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "# Define data loader with batch_size 3, dropping the last batch if batch_size < 3, with random shuffle\n",
    "loader = DataLoader(data, batch_size=3, drop_last=True, shuffle=True)\n",
    "\n",
    "# Loop over the full dataset twice, shuffling each time!\n",
    "for i in range(2):\n",
    "    print('Loop', i)\n",
    "    for index, batch_data in enumerate(loader):\n",
    "        print(index, batch_data)\n",
    "\n",
    "# Now manually set the seed each time to ensure the batches are loaded the same way at each epoch\n",
    "print('\\nRepeating by setting the seed')\n",
    "for i in range(2):\n",
    "    print('Loop',i)\n",
    "    torch.manual_seed(1)\n",
    "    for index, batch_data in enumerate(loader):\n",
    "        print(index,batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating your own dataset\n",
    "\n",
    "For your research, often you will want to create our own dataset with handy utilities. You can define your own dataset and use with the `DataLoader` as long as it's either iterable (i.e. implements `__iter__` built-in method) or supports `len` function and an index access, i.e. `__len__` and `__getitem__` support.\n",
    "\n",
    "Let's create a trivial example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([24, 89, 58, 31, 46, 33, 92,  6, 59, 86])\n",
      "1 tensor([73, 20, 55, 14, 23, 84, 29, 49, 77, 70])\n",
      "2 tensor([26, 54,  1, 56, 98, 90, 45, 93, 71, 13])\n",
      "3 tensor([ 8, 94, 34, 18, 63, 22, 64, 75, 44, 57])\n",
      "4 tensor([38, 96, 79, 60, 19, 80, 25, 37, 72, 41])\n",
      "5 tensor([ 9,  5, 27, 32, 95,  2, 81,  0, 51, 28])\n",
      "6 tensor([ 3, 35, 76, 36,  4, 48, 68, 11, 42, 99])\n",
      "7 tensor([67, 47, 10, 17, 16, 15, 52, 97, 88, 87])\n",
      "8 tensor([69, 21, 30, 74, 66, 83, 82, 62, 78, 39])\n",
      "9 tensor([65, 43, 91, 40, 50, 61,  7, 85, 12, 53])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class toy_dataset:\n",
    "\n",
    "    # How to initialize the dataset\n",
    "    def __init__(self):\n",
    "        self._data = tuple(range(100))\n",
    "\n",
    "    # Length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    # Method to fetch a specific entry in the dataset\n",
    "    def __getitem__(self,index):\n",
    "        time.sleep(0.1)\n",
    "        return self._data[index]\n",
    "\n",
    "# Initialize the dataset\n",
    "data = toy_dataset()\n",
    "\n",
    "# Build a load based on it with batch_size 10\n",
    "loader = DataLoader(data, batch_size=10, shuffle=True)\n",
    "\n",
    "# Loop over your toy dataset, print the data!\n",
    "for index, batch_data in enumerate(loader):\n",
    "    print(index, batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which is very slow because our dataset takes 0.1 second per data element access, or 1 second per batch :( While we put `time.sleep(0.1)` intentionally, this (=slow-down for per-sample data yield) can happen in reality. Perhaps you are forced to read each data sample from a file-system (i.e. \"disk\") each time because your data is too big to be stored in memory, or maybe you have to pre-process your data with complicated procedures. \n",
    "\n",
    "There is a simple way to speed this up this by setting another `DataLoader` constructor argument: `num_workers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([95, 71, 31, 39, 54, 24, 11, 14, 61, 21])\n",
      "1 tensor([73, 60, 32,  6, 47, 81, 15, 63, 17, 13])\n",
      "2 tensor([62, 99, 35, 70, 41, 53, 72, 57, 28, 65])\n",
      "3 tensor([91, 76, 51, 30, 49,  1, 23, 59, 42, 82])\n",
      "4 tensor([86, 50,  3, 94, 96, 40, 26, 36, 52, 69])\n",
      "5 tensor([66, 18, 33,  7, 27, 87, 88,  9, 25, 90])\n",
      "6 tensor([38, 67, 93, 45, 89, 92, 84, 44, 19, 79])\n",
      "7 tensor([ 2, 58, 56, 46, 97, 10,  0, 29, 78, 83])\n",
      "8 tensor([74, 37, 68, 55,  4, 20, 48, 80, 85, 98])\n",
      "9 tensor([ 8,  5, 34, 77, 64, 16, 12, 75, 43, 22])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(data, batch_size=10, shuffle=True, num_workers=5)\n",
    "\n",
    "for index, batch_data in enumerate(loader):\n",
    "    print(index,batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting `num_workers=5`, we told the `DataLoader` to use 5 separate _workers_ (processes) each responsible for fetching data in parallel. This is one of the simplest way to parallelize your data streaming.  In this tutorial, we don't cover a multi-GPU nor multi-node-multi-GPU data distribution. But tools are provided for those as well (e.g. Pytorch provides `DistributeDataParallel`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating `DataLoader` with the MNIST dataset\n",
    "\n",
    "Now let's create MNIST dataset with `batch_size=32`, `shuffle=True`, `num_workers=4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=32,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=5,\n",
    "                                     pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above introduces only 1 additional argument: `pin_memory=True`. This can speed up data transfer to GPU, at the cost of some resource overhead. Read [here](https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/) for more details. If you are not sure about the details, set to `True` when using GPU.\n",
    "\n",
    "So let's play with it! First of all, it has the concept of \"length\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of DataLoader: 1875\n",
      "By the way, batch size * length = 60000\n"
     ]
    }
   ],
   "source": [
    "print('length of DataLoader:',len(loader))\n",
    "print('By the way, batch size * length =', loader.batch_size * len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the data total statistics is 60,000 which coincides with the length of `DataLoader` instance and the batch size where the latter is the unit of batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "tensor([9, 4, 5, 8, 2, 2, 1, 3, 4, 4, 4, 4, 6, 2, 1, 4, 1, 4, 9, 1, 6, 3, 6, 4,\n",
      "        6, 1, 4, 6, 2, 3, 1, 4])\n",
      "Iteration 1\n",
      "tensor([0, 2, 8, 4, 5, 7, 9, 6, 3, 6, 7, 6, 3, 8, 0, 4, 8, 0, 8, 6, 6, 1, 4, 7,\n",
      "        2, 2, 1, 5, 7, 4, 1, 3])\n",
      "Iteration 2\n",
      "tensor([7, 8, 4, 4, 8, 7, 4, 5, 3, 5, 6, 8, 4, 3, 9, 6, 8, 6, 4, 2, 9, 4, 3, 8,\n",
      "        1, 1, 3, 5, 4, 6, 5, 0])\n",
      "Iteration 3\n",
      "tensor([8, 3, 0, 4, 5, 4, 3, 3, 9, 6, 3, 8, 9, 1, 8, 4, 3, 5, 9, 0, 1, 4, 2, 0,\n",
      "        2, 0, 8, 0, 6, 2, 2, 2])\n",
      "Iteration 4\n",
      "tensor([9, 0, 7, 2, 4, 4, 2, 8, 6, 0, 1, 1, 0, 4, 6, 9, 8, 5, 3, 5, 3, 3, 1, 8,\n",
      "        2, 8, 2, 9, 9, 5, 8, 3])\n",
      "Iteration 5\n",
      "tensor([6, 3, 8, 9, 7, 1, 3, 9, 1, 1, 5, 2, 9, 3, 7, 8, 2, 3, 9, 1, 5, 4, 8, 2,\n",
      "        4, 0, 9, 5, 6, 6, 1, 8])\n",
      "Iteration 6\n",
      "tensor([6, 1, 5, 2, 5, 9, 4, 4, 2, 5, 0, 3, 1, 3, 8, 6, 3, 7, 8, 7, 1, 2, 6, 8,\n",
      "        2, 4, 7, 7, 9, 1, 1, 2])\n",
      "Iteration 7\n",
      "tensor([8, 1, 5, 7, 0, 9, 8, 5, 8, 1, 6, 0, 0, 6, 2, 9, 9, 5, 8, 7, 7, 1, 9, 1,\n",
      "        9, 2, 0, 2, 9, 9, 1, 0])\n",
      "Iteration 8\n",
      "tensor([4, 5, 1, 4, 3, 8, 3, 6, 2, 8, 0, 3, 1, 6, 7, 2, 3, 5, 0, 0, 7, 2, 2, 3,\n",
      "        6, 3, 0, 0, 0, 7, 1, 7])\n",
      "Iteration 9\n",
      "tensor([8, 9, 8, 8, 5, 0, 7, 4, 6, 7, 4, 0, 3, 1, 6, 5, 9, 1, 0, 2, 5, 4, 3, 8,\n",
      "        8, 5, 2, 6, 7, 9, 6, 5])\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator which can cycle multiple times through the same dataloader\n",
    "from itertools import cycle\n",
    "iter = cycle(loader)\n",
    "\n",
    "# Loop over 10 entries in the loader (10 batches)\n",
    "for i in range(10):\n",
    "    # Fetch a batch\n",
    "    batch = next(iter)\n",
    "\n",
    "    # Print the iteration number\n",
    "    print('Iteration',i)\n",
    "\n",
    "    # Print the digit labels for that batch\n",
    "    print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and this is how `data` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of an image batch data torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print('Shape of an image batch data', batch[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which is quite naturally batch of 32 images of size 28x28.\n",
    "\n",
    "## 3. MNIST classification using MLP\n",
    "\n",
    "Let's try classifying hand-written digits using an MLP!\n",
    "\n",
    "### 3.1 Model definition\n",
    "We follow a similar approach we have taken in the previous notebook where we tried a logistic regression using a 2-layer perceptron with a LeakyReLU activation function between the two layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, num_filters=16):\n",
    "        # Initialize the underlying torch.nn.Module parent class\n",
    "        super().__init__()\n",
    "        \n",
    "        # MLP w/ 2 hidden layers, 128 neurons each\n",
    "        self._classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28*28, num_filters), \n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(num_filters,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the image as a 1D array (to be fed to the MLP)\n",
    "        x_1d = x.view(-1, np.prod(x.size()[1:]))\n",
    "\n",
    "        # Pass through the MLP\n",
    "        return self._classifier(x_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Train loop function\n",
    "Next, let's define a train and test loop function. This is pretty much copied from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 06:18:46.277975: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-10 06:18:46.296738: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749536326.319667     101 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749536326.325938     101 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749536326.342945     101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749536326.342980     101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749536326.342982     101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749536326.342984     101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-10 06:18:46.349198: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Module which draws loading bars (makes it easier to wait...)\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "def run_train(model, loader,  \n",
    "              num_iterations=100, log_dir='log',\n",
    "              lr=0.001, optimizer='SGD', device=None):\n",
    "    print(\"\\nTraining...\")\n",
    "    tstart = time.time()\n",
    "    if log_dir:\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim,optimizer)(model.parameters(),lr=lr)\n",
    "    \n",
    "    iteration = 0\n",
    "    pbar = tqdm(total=num_iterations, position=0, leave=True)\n",
    "    while iteration < num_iterations:\n",
    "        for data, label in loader:\n",
    "            \n",
    "            if device:\n",
    "                data, label = data.to(device), label.to(device)\n",
    "\n",
    "            loss = criterion(model(data), label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if log_dir: \n",
    "                writer.add_scalar('loss/train', loss.item(), iteration)\n",
    "\n",
    "            # Brake if we consumed all iteration counts\n",
    "            iteration += 1\n",
    "            pbar.update(1)\n",
    "            if iteration >= num_iterations:\n",
    "                break\n",
    "    print('done', time.time()-tstart, '[s]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!\n",
    "\n",
    "Let's train for 4000 steps using Adam optimizer. Also, the number of filters (hidden neurons) is default = 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [1:26:45<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 5205.63937664032 [s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_a = MLP(16)\n",
    "\n",
    "# run_train(model_a, loader, 4000, log_dir='mnist_mlp/filter16', optimizer='Adam')\n",
    "run_train(model_a, loader, 4000, log_dir=None, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir mnist_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Exercise A\n",
    "\n",
    "Repeat the same training for `model_b` = `MLP` with 32 filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Exercise B\n",
    "\n",
    "1. Repeat the exercise A and measure how long it takes in wall-time.\n",
    "2. Repeat again, but this time with GPU enabled, and measure how long it takes.\n",
    "\n",
    "You probably see a very similar amount of time taken for both cases. This is because parallelizable fraction of computation is not dominating in the overall computing time (and especially when most time may be taken to copy data onto gpu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on test dataset\n",
    "Both models seem to be trained OK. Let's benchmark their performance using the test dataset! Pytorch provides 10,000 MNIST dataset that is separate from the training set by simply setting the flag `train=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use prepared data handler from pytorch (torchvision)\n",
    "test_dataset = datasets.MNIST(LOCAL_DATA_DIR, train=False, download=True,\n",
    "                              transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=4,\n",
    "                                          pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference loop function\n",
    "\n",
    "Let's now write a function to run the inference. This would be similar to the training loop. A key difference is to use a scope `with torch.set_grad_enabled(False)` which disables gradient calculation and caching of intermediate data for it. This results in less memory usage, so you should do this when you run your model for inference and not training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(model, loader, device=None):\n",
    "\n",
    "    label_v, softmax_v = [],[]\n",
    "    softmax   = torch.nn.Softmax(dim=1)\n",
    "    f = IntProgress(min=0,max=int(len(loader)),bar_style='info')\n",
    "    display(f)\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        for data,label in loader:\n",
    "            if device:\n",
    "                data,label = data.to(device), label.to(device)\n",
    "            label_v.append  ( label.detach().reshape(-1)   )\n",
    "            softmax_v.append( softmax(model(data)).detach())\n",
    "            f.value += 1\n",
    "    return torch.concat(label_v).cpu().numpy(), torch.concat(softmax_v).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Exercise C\n",
    "1. Run the inference for `model_a` and `model_b`.\n",
    "2. Using the results, compute the accuracy over the whole test dataset for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Exercise D\n",
    "\n",
    "1. Count the number of parameters in our `model_a`\n",
    "2. How about `model_b`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
